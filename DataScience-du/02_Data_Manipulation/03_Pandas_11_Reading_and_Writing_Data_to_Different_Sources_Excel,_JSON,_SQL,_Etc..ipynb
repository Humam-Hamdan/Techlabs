{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb20ffa2",
   "metadata": {},
   "source": [
    "# Chapter 11 - Reading and Writing Data to Different Sources - Excel, JSON, SQL, Etc.\n",
    "### Hey Techie,   \n",
    "Welcome to the final notebook of this Pandas tutorial series. We encourage you to take this notebook as a template to code along the instruction video, which you may find at: https://youtu.be/N6hyN6BW6ao. In the instruction video, Corey explains how to read and write different data formats using Pandas. To work with Excel files, you need to install the packages *xlwt* (https://pypi.org/project/xlwt/), *openpyxl* (https://pypi.org/project/openpyxl/), and *xlrd* (https://pypi.org/project/xlrd/) first - this is explained at 7:30 min. Please note that you can skip the part where Corey explains how to handle data from SQL databases (17:00-28:00 min.). As always, at the end, you may find some practice tasks.\n",
    "\n",
    "**Here you may find the Pandas documentation:** https://pandas.pydata.org/docs/reference/index.html\n",
    "\n",
    "#### Have fun! :-)   \n",
    "    \n",
    "*Video length*: 22 minutes   \n",
    "*Self-study time*: 22 minutes   \n",
    "*Total*: **44 minutes**\n",
    "<hr style=\"border:2px solid gray\"> </hr>   \n",
    "\n",
    "## Real-word Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9c8092-9f94-4838-8b6e-35742bc93834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These options help us to inspect our data more easily.\n",
    "pd.set_option(\"display.max_columns\", 85)\n",
    "pd.set_option(\"display.max_rows\", 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fdd5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These commands load the same survey data Corey is using in his video.\n",
    "df = pd.read_csv(\"data/survey_results_public.csv\", index_col = \"Respondent\")\n",
    "schema_df = pd.read_csv(\"data/survey_results_schema.csv\", index_col = \"Column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START YOUR CODE HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978a640-70c7-4d8a-892f-5c629f83e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = df['Country'] == 'India'\n",
    "india_df = df.loc[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785905ff-3993-4626-8fc7-75c2c8d88575",
   "metadata": {},
   "outputs": [],
   "source": [
    "india_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1afcfd-633c-434c-bbe2-0b0c65f75f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "india_df.to_csv('data/mod_india.csv')\n",
    "# to save into a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf8d653-a49c-4e89-af00-af75a966874d",
   "metadata": {},
   "source": [
    "You can make it a tsv with .to_csv('filename.tsv', sep=\\t)\n",
    "\n",
    "it also works with read_csv\n",
    "\n",
    ".to_excel('filename') for xls, xlsx\n",
    "\n",
    ".read_excel('filename', index_col='colname') to read\n",
    "\n",
    ".to_json('filename') for JSON, deafult dict-like, if you want list-like => .to_json('filename', orient='records', lines=True)\n",
    "\n",
    ".read_json('filename', orient='records', lines=True), you need to account for changes in the export arsg when reading json."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463374de-9a8a-4351-a566-f62813b89e0b",
   "metadata": {},
   "source": [
    "Assuming you already have a ready-to-use DB.\n",
    "\n",
    "SQLAlchemy to interact with DBs.\n",
    "\n",
    "for postgreq => psycopg2-binary.\n",
    "\n",
    "create_engine from sqlalchemy\n",
    "\n",
    "engine = create_engine('SQLconnectionString')\n",
    "\n",
    "df.to_sql('tablename', DBConnection (engine) )\n",
    "\n",
    "to re-write the data or if tablename exists\n",
    "\n",
    "df.to_sql('tablename', DBConnection (engine) , if_exists='replace' )\n",
    "\n",
    ".read_sql('tablename', DBConnectino, index='colanme')\n",
    "\n",
    ".read_sql_query('SQLQuery', DBConnection, index='colname')\n",
    "\n",
    "you can pass urls instead of fileenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b97ba1c",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>   \n",
    "   \n",
    "## Practice Tasks   \n",
    "#### 1. In the following tasks, we will work with an e-commerce dataset from the Kaggle platform (https://www.kaggle.com/carrie1/ecommerce-data). This dataset is stored under data/transaction_details.csv and contains transaction details of an online store from the end of 2010 to the end of 2011. First, the dataset has to be loaded. Thereby, four parameters of the read_csv method have to be adjusted: sep, na_values, parse_dates, and date_parser. After the dataset has been loaded, all rows should be removed where both the CustomerID and Description column contain NaN values. The DataFrame should be saved as *df*.   \n",
    "\n",
    "<br /> \n",
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"red\"><b>Hints (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>To determine the used separator, one could open the CSV file with a text editor.</li>\n",
    "        <li>To determine the identifier for NaN values, you should search through the CSV file inside the text editor, for example, with cmd f. Look up terms such as \"NA,\" \"MISSING,\" \"NO DATA,\" etc.</li>\n",
    "        <li>The date's format is month/day/year hour:minute. How does this translate to a date format code?</li>\n",
    "    </ul>\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46fa77-ca69-4831-96e5-31b84f93d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START YOUR CODE HERE.\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462b01a-dd4b-4744-a1db-9adcb3f39e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_parser = lambda x: datetime.strptime(x, \"%m/%d/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55daeaff-4f4c-42b5-9e43-b96eb0c4174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_csv('data/transaction_details.csv', sep=';', na_values=['MISSING_DATA'] ,  parse_dates=['InvoiceDate'] , date_parser=d_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c48ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_na = ['CustomerID', 'Description']\n",
    "pdf['CustomerID'] = pdf['CustomerID'].astype(float)\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f292e4d-c5aa-4b77-a6d0-8b96fc44ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121e1c36-16b9-4737-b769-44c9ad69b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='all', subset=check_na, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d597f-9490-4b17-bd54-33eccaae05e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InvoiceDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3265fd2-f99b-4c87-8f07-3c9703a50d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END YOUR CODE HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL TESTS YOUR RESULTS.\n",
    "import numpy as np\n",
    "assert df.shape == (540455, 8), \"Your DataFrame seems to have the wrong shape!\"\n",
    "assert np.dtype('<M8[ns]') == df[\"InvoiceDate\"].dtype, \"The InvoiceDate column should contain DateTime objects!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adbc997",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Solution (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <code>import pandas as pd</code><br />\n",
    "    <code>from datetime import datetime</code><br />\n",
    "    <code>d_parser = lambda x: datetime.strptime(x, \"%m/%d/%Y %H:%M\")</code><br />\n",
    "    <code>df = pd.read_csv(\"data/transaction_details.csv\", sep = \";\", na_values = \"MISSING_DATA\",</code><br /> \n",
    "    <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;parse_dates= [\"InvoiceDate\"], date_parser = d_parser)</code><br />\n",
    "    <code>df.dropna(how = \"all\", subset = [\"Description\", \"CustomerID\"], inplace = True)</code><br />\n",
    "</p>\n",
    "</details>   \n",
    "   \n",
    "#### 2. Calculate the revenue during January in 2011 and store it in a variable named *revenue_january*.   \n",
    "\n",
    "<br /> \n",
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"red\"><b>Hints (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>The arithmetic product of the two columns Quantity and UnitPrice yield the overall price per order necessary to calculate the revenue.</li>\n",
    "        <li>Remind yourself how to index specific periods if a DataFrame's index contains DateTime objects.</li>\n",
    "    </ul>\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f491ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START YOUR CODE HERE.\n",
    "\n",
    "revenue_january = \n",
    "\n",
    "# END YOUR CODE HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ea9934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS CELL TESTS YOUR RESULTS.\n",
    "assert revenue_january == 560000.2599999999, \"Your result seems to be incorrect!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59624ab",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Solution (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <code>df[\"overall_price\"] = df[\"Quantity\"] * df[\"UnitPrice\"]</code><br />\n",
    "    <code>revenue_january = df.set_index(\"InvoiceDate\").loc[\"2011-01\", \"overall_price\"].sum()</code><br />\n",
    "</p>\n",
    "</details>   \n",
    "   \n",
    "#### 3. In which month during 2011 was the revenue the most? Store this month's name as a String (i.e., January) in a variable named *revenue_month*.\n",
    "<br />\n",
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"red\"><b>Hints (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>Remind yourself how to apply resampling to time series data. In this case, one needs to resample on a monthly basis.</li>\n",
    "        <li>A function called idxmax is applicable to a Series object that returns the index of a Series object's maximum rather than its value.</li>\n",
    "    </ul>\n",
    "        \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START YOUR CODE HERE.\n",
    "\n",
    "revenue_month = ...\n",
    "\n",
    "# END YOUR CODE HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5121dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL TESTS YOUR RESULTS.\n",
    "assert revenue_month == \"November\", \"Your result seems to be incorrect!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183313e3",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Solution (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <code>revenue_month = df.set_index(\"InvoiceDate\").loc[:, \"overall_price\"].resample(\"M\").sum().idxmax().month_name()</code><br />\n",
    "</p>\n",
    "</details>  \n",
    "   \n",
    "#### 4. From which country did the most orders come in November 2011? Store this country's name as a String (i.e., United States) called *country_orders*.\n",
    "<br />\n",
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"red\"><b>Hints (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>The overall approach is very similar to tasks two and three.</li>\n",
    "        <li>Which function returns unique value counts if it is called on a Series object?</li>\n",
    "    </ul>\n",
    "        \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c475c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START YOUR CODE HERE.\n",
    "\n",
    "country_orders = ...\n",
    "\n",
    "# END YOUR CODE HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6569d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL TESTS YOUR RESULTS.\n",
    "assert country_orders == \"United Kingdom\", \"Your result seems to be incorrect!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f80ceef",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Solution (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <code>country_orders = df.set_index(\"InvoiceDate\").loc[\"2011-11\", \"Country\"].value_counts().idxmax()</code><br />\n",
    "</p>\n",
    "</details>  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
