{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb20ffa2",
   "metadata": {},
   "source": [
    "# Chapter 08 - Grouping and Aggregating - Analyzing and Exploring Your Data\n",
    "### Hey Techie,   \n",
    "Welcome to the eigth notebook of this Pandas tutorial series. We encourage you to take this notebook as a template to code along the instruction video, which you may find at: https://youtu.be/txMdrV1Ut64. In the instruction video, Corey explains how to group and aggregate data using Pandas to extract meaningful insights. As always, at the end of this notebook are practice tasks to test your skills.     \n",
    "\n",
    "**Here you may find the Pandas documentation:** https://pandas.pydata.org/docs/reference/index.html\n",
    "\n",
    "#### Have fun! :-)   \n",
    "    \n",
    "*Video length*: 50 minutes   \n",
    "*Self-study time*: 50 minutes   \n",
    "*Total*: **100 minutes**\n",
    "<hr style=\"border:2px solid gray\"> </hr>   \n",
    "\n",
    "## Real-word Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fdd5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the convention used to import Pandas.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe51d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These options help us to inspect our data more easily.\n",
    "pd.set_option(\"display.max_columns\", 85)\n",
    "pd.set_option(\"display.max_rows\", 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd61776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These commands load the same survey data Corey is using in his video.\n",
    "df = pd.read_csv(\"data/survey_results_public.csv\", index_col = \"Respondent\")\n",
    "schema_df = pd.read_csv(\"data/survey_results_schema.csv\", index_col = \"Column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdbd60d-e659-45a1-b00b-92d921dc4965",
   "metadata": {},
   "source": [
    "START YOUR CODE HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ed9dc-11bb-421a-a87c-428b0b088745",
   "metadata": {},
   "source": [
    "Checking salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649481b-6307-4a36-b0cd-df8ce3127295",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ConvertedComp'].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62932b7a-b978-4b1d-9639-82969a63e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ConvertedComp'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065d046-6da7-4b8d-afaa-ffd929815733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac513e86-e8b0-4b1d-84d4-abda46ccf658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3027fb3-8618-4f95-a43f-e7870744d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hobbyist'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b864ee-cbe9-4ab5-b7d9-62c2de4a0bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SocialMedia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64ae63a-a685-4cb1-878d-1be599f8cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df.loc['SocialMedia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e2eb6-3dc0-407d-b3ca-1b8fe7d30c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SocialMedia'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d0548-10cb-4237-bed5-28df0b76c0a1",
   "metadata": {},
   "source": [
    "Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3493ee-4774-408a-bf31-997b539ee4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165d4e0-27aa-4a70-b5e4-bd1dce4a851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_groups = df.groupby(['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1356a196-1775-4afc-872c-191255337369",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_groups.get_group('United States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a6328-e356-4b9a-bed4-cd82615cf54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_us = df['Country'] == 'United States'\n",
    "df.loc[filt_us]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d7cd6-4c4e-4725-b80c-38b9040d2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_groups['SocialMedia'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6dc92-7c31-4149-a02d-e04a75144853",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_groups['SocialMedia'].value_counts().loc['India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c55dad-2e38-406a-97b3-cfc8c1288aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_groups['ConvertedComp'].agg(['median', 'mean']).loc['Canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc113434-c202-403e-a992-97ea51b632c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_country = df['Country'] == 'India'\n",
    "df.loc[filter_country]['LanguageWorkedWith'].str.contains('Python').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c39d1f3-d930-48ce-9f5c-03051b9d7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_groups['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f3eeb-fbb9-43af-8481-8b1c817b1f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_respondents = df['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7318a2fc-bb6e-45bc-8126-7c4a6d9affd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_knows_python = country_groups['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab696b-d93a-4b5f-8da3-50c19410cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_df = pd.concat([country_respondents, country_knows_python], axis='columns', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb6179-4be9-491f-82f7-3a9254381f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b57dd-207f-4341-b97f-0978085350a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_df.rename(columns={'count':'NrRespondents', 'LanguageWorkedWith':'NrKnowsPython'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2074de-ef07-4ea6-beea-f8dfde7270d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_df['PercKnowsPython'] = (100 * python_df['NrKnowsPython'] / python_df['NrRespondents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6fd29e-5faa-4bf2-be5d-c2edb1f18ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882bdc46-db04-4799-b84f-11a91fef5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_df.sort_values(by='PercKnowsPython', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2529ef9f-9ffe-4a19-a04d-49cc3455af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e91340-0e69-42fd-98c8-15233d00f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_df.loc['Egypt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b97ba1c",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>   \n",
    "   \n",
    "## Practice Tasks   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15892dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a clean DataFrame.\n",
    "df = pd.read_csv(\"data/survey_results_public.csv\", index_col = \"Respondent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e89bef",
   "metadata": {},
   "source": [
    "#### 1. Create an overview of the coding experience (\"YearsCode\" column; mean) and the compensation (\"ConvertedComp\"; median) per country. To do so, change the data type from the \"YearsCode\" column to float (replace \"Less than 1 year\" with 0 and \"More than 50 years\" with 51). Please return a DataFrame named *country_overview* that looks the following:    \n",
    "| Country     |   YearsCode |   ConvertedComp |\n",
    "|:------------|------------:|----------------:|\n",
    "| Afghanistan |     7.31707 |            6222 |\n",
    "| Albania     |     6.51807 |           10818 |\n",
    "| ...         |     ...     |            ...  |\n",
    "\n",
    "   \n",
    "   \n",
    "<br /> \n",
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"red\"><b>Hints (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>First, replace the \"less than\" and \"more than\" statements within the YearsCode column. This way, you can set the data type of this column to float.</li>\n",
    "        <li>Group by the countries column.</li>\n",
    "        <li>To apply different aggregation methods to different columns, pass a dictionary to the agg method. The dictionary's keys correspond to the column names you want to aggregate, and the values indicate the specific aggregation method. For example, groupby_object.agg({\"Column 1\": \"mean\", \"Column 2\": \"median\"}).</li>\n",
    "    </ul>\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c48ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START YOUR CODE HERE.\n",
    "\n",
    "df['YearsCode'] = df['YearsCode'].replace({'Less than 1 year': '0', 'More than 50 years': '51'})\n",
    "\n",
    "df['YearsCode'] = df['YearsCode'].apply(lambda x: float(x))\n",
    "\n",
    "country_groups = df.groupby(['Country'])\n",
    "\n",
    "years_code_series = country_groups['YearsCode'].mean()\n",
    "\n",
    "convertedcomp_series = country_groups['ConvertedComp'].median()\n",
    "\n",
    "country_overview = pd.concat([years_code_series, convertedcomp_series], axis='columns')\n",
    "\n",
    "#country_overview\n",
    "\n",
    "# END YOUR CODE HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL TESTS YOUR RESULTS.\n",
    "assert type(country_overview) == type(pd.DataFrame([])), \"Please return a DataFrame!\"\n",
    "assert country_overview.loc[\"Germany\", \"YearsCode\"] == 12.784108460614382, \"Your results seem to be incorrect!\"\n",
    "assert country_overview.loc[\"United States\", \"ConvertedComp\"] == 110000.0, \"Your results seem to be incorrect!\"\n",
    "assert country_overview.loc[\"India\", \"ConvertedComp\"] == 10080.0, \"Your results seem to be incorrect!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adbc997",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Solution (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <code>df[\"YearsCode\"].replace(\"Less than 1 year\", 0, inplace = True)</code><br />\n",
    "    <code>df[\"YearsCode\"].replace(\"More than 50 years\", 51, inplace = True)</code><br />\n",
    "    <code>df[\"YearsCode\"] = df[\"YearsCode\"].astype(float)</code><br />\n",
    "    <code>groupby_object = df.groupby(\"Country\")</code><br />\n",
    "    <code>country_overview = groupby_object.agg({\"YearsCode\": \"mean\", \"ConvertedComp\": \"median\"})</code><br />\n",
    "</p>\n",
    "</details>   \n",
    "   \n",
    "#### 2. Create an overview that shows what percentage of respondents are very satisfied (\"JobSat\" column) with their current job per country (\"Country\" column). Return a Series object named *satisfied_percentage* that is sorted in descending order and looks the following:   \n",
    "|             |          |\n",
    "|:------------|---------:|\n",
    "| Timor-Leste | 1        |\n",
    "| Belize      | 0.666667 |\n",
    "| ...         | ...      |\n",
    "\n",
    "<br /> \n",
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"red\"><b>Hints (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>Group by the country.</li>\n",
    "        <li>Then determine per country how often a participant answered \"Very Satisfied\" to the job satisfaction question.</li>\n",
    "        <li>Determine how many participants there was per country. Note that you previously excluded all participants who did not answer both questions.\n",
    "Arithmetic operations in Pandas are always performed so that the same indices are offset against each other. Your groupby-DataFrame and the CountryCount-DataFrame both have the countries as the index.</li>\n",
    "    </ul>\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f491ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This drops every participant that did not answer both questions.\n",
    "task_df = df[[\"JobSat\", \"Country\"]].dropna()\n",
    "# START YOUR CODE HERE.\n",
    "\n",
    "group = task_df.groupby(['Country'])\n",
    "\n",
    "x = group.value_counts(normalize=True).loc[:, 'Very satisfied']\n",
    "\n",
    "x.loc[['Germany', 'United States', 'India']]\n",
    "\n",
    "# END YOUR CODE HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ea9934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS CELL TESTS YOUR RESULTS.\n",
    "assert type(satisfied_percentage) == type(pd.Series([], dtype = \"int64\")), \"Please return a Series!\"\n",
    "assert satisfied_percentage.loc[\"Germany\"] == 0.24616433685646097, \"Your results seem to be incorrect!\"\n",
    "assert satisfied_percentage.loc[\"United States\"] == 0.3435486180724617, \"Your results seem to be incorrect!\"\n",
    "assert satisfied_percentage.loc[\"India\"] == 0.16410992164220284, \"Your results seem to be incorrect!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59624ab",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Solution (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <code>task_df = df[[\"JobSat\", \"Country\"]].dropna()</code><br />\n",
    "    <code>groupby_object = task_df.groupby(\"Country\")</code><br />\n",
    "    <code>satisfied_per_country = groupby_object[\"JobSat\"].apply(lambda x: (x == \"Very satisfied\").sum())</code><br />\n",
    "    <code>respondents_per_country = df[\"Country\"].value_counts()</code><br />\n",
    "    <code>satisfied_percentage = (satisfied_per_country/respondents_per_country).sort_values(ascending = False)</code><br />\n",
    "</p>\n",
    "</details>   \n",
    "   \n",
    "#### 3. The mean is known to be strongly influenced by outliers. Therefore, create an overview showing how many participants per country receive a higher compensation (ConvertedComp column) than the respective country average. Contrast this column with how many people from each country (Country column) generally participated in the study. The first line of code is already given to include only participants that answered both questions. Please return a DataFrame named *comp_average* that looks like this:   \n",
    "| Country     |   Number of respondents with an above average compensation |   Total number of respondents |\n",
    "|:------------|-----------------------------------------------------------:|------------------------------:|\n",
    "| Afghanistan |                                                          2 |                            12 |\n",
    "| Albania     |                                                         14 |                            50 |\n",
    "| ...         |                                                        ... |                           ... |   \n",
    "   \n",
    "\n",
    "<br />\n",
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"red\"><b>Hints (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>There are several ways how to solve this task.</li>\n",
    "        <li>First, in any case, one must calculate the average compensation per country with a groupby operation.</li>\n",
    "        <li>Second, one should check per participant whether their compensation is above or below the mean compensation of their country. The resulting boolean values should be stored in a new column in the DataFrame.</li>\n",
    "        <li>Then one can perform a final groupby operation on the DataFrame by the countries. For the just determined above_average column, one determines the sum (because boolean values are handled like 0 and 1), and for the country column, the count.</li>\n",
    "    </ul>\n",
    "        \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37a3ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This drops every participant that did not answer both questions.\n",
    "comp_average = df[[\"Country\", \"ConvertedComp\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b992b280-983d-41a6-8efe-79f3a399eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START YOUR CODE HERE.\n",
    "\n",
    "## SOLUTION\n",
    "\n",
    "country_mean = df.groupby(\"Country\").agg({\"ConvertedComp\": \"mean\"})\n",
    "comp_average[\"above_average\"] = [compensation > country_mean.loc[country, \"ConvertedComp\"]\n",
    "                            for compensation, country in zip(comp_average[\"ConvertedComp\"].values,\n",
    "                            comp_average[\"Country\"].values)]\n",
    "comp_average = comp_average.groupby(\n",
    "    \"Country\").agg({\"above_average\": \"sum\", \"Country\": \"count\"}).rename(\n",
    "    {\"above_average\": \"Number of respondents with an above average compensation\",\n",
    "     \"Country\": \"Total number of respondents\"}, axis = 1)\n",
    "\n",
    "    \n",
    "# END YOUR CODE HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5121dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL TESTS YOUR RESULTS.\n",
    "import numpy as np\n",
    "assert type(comp_average) == type(pd.DataFrame([])), \"Please return a DataFrame!\"\n",
    "assert comp_average.shape == (161, 2), \"Your DataFrame seems to have the wrong dimensions!\"\n",
    "assert np.array_equal(comp_average.loc[\"United States\"].to_numpy(), [1911, 14981]), \"Your results seem to be wrong!\"\n",
    "assert np.array_equal(comp_average.loc[\"Germany\"].to_numpy(), [466, 3778]), \"Your results seem to be wrong!\"\n",
    "assert np.array_equal(comp_average.loc[\"India\"].to_numpy(), [677, 3999]), \"Your results seem to be wrong!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183313e3",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Solution (click to expand)</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <code>comp_average = df[[\"Country\", \"ConvertedComp\"]].dropna()</code><br />\n",
    "    <code>country_mean = df.groupby(\"Country\").agg({\"ConvertedComp\": \"mean\"})</code><br />\n",
    "    <code>comp_average[\"above_average\"] = [compensation > country_mean.loc[country, \"ConvertedComp\"]</code><br />\n",
    "    <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for compensation, country in zip(comp_average[\"ConvertedComp\"].values,</code><br /> \n",
    "    <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;comp_average[\"Country\"].values)]</code><br />\n",
    "    <code>comp_average = comp_average.groupby(</code><br />\n",
    "    <code>&nbsp;&nbsp;&nbsp;&nbsp;\"Country\").agg({\"above_average\": \"sum\", \"Country\": \"count\"}).rename(</code><br />\n",
    "    <code>&nbsp;&nbsp;&nbsp;&nbsp;{\"above_average\": \"Number of respondents with an above average compensation\",</code><br />\n",
    "    <code>&nbsp;&nbsp;&nbsp;&nbsp; \"Country\": \"Total number of respondents\"}, axis = 1)</code><br />\n",
    "</p>\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
